{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font size=\"6\">**Introduction**</font>\n",
        "\n",
        "This project analyzes city-level waste management data sourced from the World Bank Group.\n",
        "The data provides information on municipal solid waste (MSW) generation, recycling and composting rates, waste treatment methods, and financial aspects related to waste management.\n",
        "\n",
        "---\n",
        "# <font size=\"6\">**Purpose**</font>\n",
        "\n",
        "The main purpose of this analysis is to:\n",
        "- Understand how cities and countries manage municipal solid waste\n",
        "- Identify trends in waste generation and waste diversion (recycling and composting)\n",
        "- Highlight opportunities for improvement in waste management practices\n",
        "\n",
        "---\n",
        "# <font size=\"6\">**Scope**</font>\n",
        "\n",
        "This analysis will cover:\n",
        "- Total MSW generation at both the country and city levels\n",
        "- Diversion rates (recycling and composting) by city and country\n",
        "- Waste management costs and strategies for disposal\n",
        "- The geographical distribution of MSW and diversion efforts\n",
        "\n",
        "We will focus on a dataset provided by the World Bank, which includes information for several countries and cities around the world.\n",
        "\n",
        "---\n",
        "# **How the Data is Accessed**\n",
        "\n",
        "To begin the analysis:\n",
        "1. We connect to Google Drive using Colab’s `drive.mount` function to access the data stored in the cloud.\n",
        "2. The dataset is loaded into a pandas DataFrame (`df`), which is used for data manipulation and analysis.\n",
        "3. We inspect the data by looking at the columns and unique values within them to better understand the structure.\n",
        "\n",
        "The data file, named `city_level_data_0_0.csv`, contains detailed information about solid waste management practices across different cities and countries.\n",
        "\n",
        "---\n",
        "# **Major Steps of the Project**\n",
        "\n",
        "The analysis is divided into the following major steps:\n",
        "1. **Connect to Google Drive and Aquiring the Data**:\n",
        "   - Mount Google Drive to access the CSV file in your Colab environment.\n",
        "2. **Load and Inspect the Dataset**:\n",
        "   - Load the data into pandas and check the columns, types, and unique values (countries and cities).\n",
        "3. **Group and Analyze the Data**:\n",
        "   - Summarize waste generation by country and city.\n",
        "   - Calculate diversion rates (recycling and composting percentages).\n",
        "   - Group cities by waste generation and diversion rates to identify trends.\n",
        "4. **Save Processed Data**:\n",
        "   - After cleaning and transforming the data, save the results as a new CSV file for future reference.\n",
        "\n"
      ],
      "metadata": {
        "id": "sPqleOLgQ4Wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font size=\"6\">**Step 1: Connect to Google Drive and Acquire the Data**</font>\n",
        "\n",
        "In the first step of the project, we will connect to Google Drive to access the data stored in the cloud. The dataset we're using is obtained from the World Bank Group, specifically the **[World Bank's Waste Management Data](https://data.worldbank.org/indicator/EN.ATM.WAST.ZS)**. The data file, named `city_level_data_0_0.csv`, contains information on solid waste management practices across various cities and countries.\n",
        "\n",
        "---\n",
        "## **Acquiring the Data**\n",
        "\n",
        "The dataset is publicly available for download on the World Bank Group website. To download the dataset:\n",
        "\n",
        "1. Visit the **[World Bank Data Portal](https://data.worldbank.org/indicator/EN.ATM.WAST.ZS)**.\n",
        "2. Navigate to the section on municipal solid waste management or search for \"waste management data.\"\n",
        "3. Download the relevant CSV file to your local system or directly to your Google Drive.\n",
        "\n",
        "Once the file is downloaded, you can upload it to your Google Drive. In this project, the data is stored in a folder called \"Colab Notebooks\" on Google Drive for easy access in the Colab environment.\n",
        "\n",
        "---\n",
        "## **1.1 Mounting Google Drive**\n",
        "\n",
        "We will use the following code to mount your Google Drive and make the file accessible:"
      ],
      "metadata": {
        "id": "iJXgZ9ewS29t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x7LcUKNmMtkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455d58fb-8097-4778-bddd-ea254ec5e1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Step 1.1\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you run this line of code, it mounts your Google Drive to the Colab environment. The drive.mount('/content/gdrive') function will prompt you to authorize access by clicking on a link and providing the necessary permissions. Once mounted, the message Mounted at /content/gdrive will appear in the output. This means your Google Drive is now linked to the Colab environment, and you can access the files stored on it.\n",
        "\n",
        "- Why this is important: Mounting Google Drive is necessary because it allows Colab to access files from your cloud storage without needing to upload them directly each time. This is particularly useful for large datasets, like the one we are using in this project."
      ],
      "metadata": {
        "id": "hgBzd_6nI05I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **1.2 Importing Libraries**\n",
        "Next, we need to import the necessary libraries. We'll use pandas to work with tables of data and numpy for numerical calculations."
      ],
      "metadata": {
        "id": "MwOd5livUyMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1.2\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6JM8h4f6uqLu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we import the two key libraries we will be using for data analysis:\n",
        "\n",
        "- numpy: A fundamental library for numerical computing. It allows us to perform complex mathematical operations and manipulate data efficiently. In this case, it will help with any calculations or transformations we need to perform on the dataset later.\n",
        "\n",
        "- pandas: A powerful data manipulation and analysis library for Python. It helps us work with tables (DataFrames) of data, allowing us to read, clean, and analyze large datasets. Pandas is particularly useful for operations like sorting, grouping, filtering, and summarizing data.\n",
        "\n",
        "These two libraries will be critical as we analyze the waste management data across different cities and countries."
      ],
      "metadata": {
        "id": "YwAoODmpMUYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **1.3 Loading the Dataset**\n",
        "After setting up the environment and importing the necessary libraries, we can now load the dataset into the Colab environment. The following line reads the dataset from your Google Drive using pandas and stores it in a variable called df. The dataset file, city_level_data_0_0.csv, contains data on waste management in various cities."
      ],
      "metadata": {
        "id": "vORWx8wZVB7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1.3\n",
        "df=pd.read_csv('gdrive/My Drive/Colab Notebooks/city_level_data_0_0.csv')"
      ],
      "metadata": {
        "id": "vh0VobN0uxAo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line of code loads the dataset from your Google Drive into a pandas DataFrame. The pd.read_csv() function is used to read CSV files and load them into a DataFrame. Here, the file path 'gdrive/My Drive/Colab Notebooks/city_level_data_0_0.csv' specifies the location of the CSV file in your Google Drive. When the file is successfully loaded, the data is stored in the variable df.\n",
        "\n",
        "- Why this is important: This step is essential because it allows us to bring the dataset into the Colab environment, making it ready for analysis. The df variable will now contain all the data from the CSV file, and we can begin manipulating it using pandas methods.\n",
        "\n",
        "- What to expect: After running this code, the data will be accessible in the df variable, which can be further explored and analyzed using various pandas functions.\n",
        "\n"
      ],
      "metadata": {
        "id": "j5MUvyZnMeyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Summary of Step 1: Connect to Google Drive and Acquire the Data**\n",
        "\n",
        "In Step 1, we began by setting up the environment to access and work with the data. First, we connected our Google Drive to the Colab environment. This is crucial because it allows us to store and retrieve the dataset directly from the cloud. By mounting the Google Drive, we ensure that the data file is easily accessible for subsequent analysis.\n",
        "\n",
        "Next, we acquired the dataset, which is publicly available from the **World Bank Group's website**. We focused on the **[World Bank's Waste Management Data](https://data.worldbank.org/indicator/EN.ATM.WAST.ZS)**, specifically the `city_level_data_0_0.csv` file. This dataset contains detailed information on waste management practices across various cities and countries.\n",
        "\n",
        "After mounting the Google Drive, we loaded the dataset into our Colab environment using Python’s `pandas` library. This allows us to easily manipulate and analyze the data. We also verified that the data was loaded correctly by inspecting the columns and ensuring the dataset was accessible.\n",
        "\n",
        "By the end of Step 1, we have successfully connected to Google Drive, acquired the data, and ensured that it is ready for analysis in the next steps. This prepares us to dive into the dataset, explore its structure, and begin cleaning and analyzing it in Step 2.\n"
      ],
      "metadata": {
        "id": "5mZDoy9_ZpRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font size=\"6\">**Step 2: Data Exploration and Preprocessing**</font>\n",
        "\n",
        "In Step 2 of this project, we will focus on understanding the structure and contents of the dataset we’ve acquired. At this stage, the data is raw and may contain some inconsistencies, missing values, or inappropriate data types. The goal of this step is to explore and clean the data so that it is ready for analysis and visualization.\n",
        "\n",
        "---\n",
        "### What we will do in this step:\n",
        "- **Explore the dataset's columns**: We will start by reviewing the columns available in the dataset to understand the variables it contains. This gives us insight into the types of information we can work with.\n",
        "- **Identify unique values**: For key columns, such as `country_name`, we will check for unique values to understand the geographical coverage of the data and ensure there are no unexpected entries or missing data.\n",
        "- **Handle data types**: Some columns may not be in the correct format for numerical analysis. We’ll convert any columns that should contain numbers (such as waste generation data) to the appropriate numeric types.\n",
        "- **Check for missing values**: We will also inspect the dataset for missing values. In real-world datasets, it’s common to encounter gaps in the data. We’ll identify these missing values and decide whether to remove them or replace them with appropriate values (e.g., the mean or median).\n",
        "\n",
        "This process is crucial because clean, well-organized data is the foundation for effective analysis. By the end of Step 2, we will have a clearer picture of the data’s structure, and we’ll be ready to start deeper analysis in the following steps.\n"
      ],
      "metadata": {
        "id": "k0W1yZN5Yz8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **2.1 Checking Unique Country Names**\n",
        "To better understand the data, it's helpful to see the unique countries represented in the dataset. The following code extracts all unique country names from the country_name column of the DataFrame."
      ],
      "metadata": {
        "id": "qGmOksRdVKm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2.1\n",
        "print(df['country_name'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ioot0l0v6K0i",
        "outputId": "c0674eaf-c04a-4676-832f-64ac9486f502"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Afghanistan' 'Angola' 'Albania' 'United Arab Emirates' 'Argentina'\n",
            " 'Armenia' 'American Samoa' 'Australia' 'Austria' 'Azerbaijan' 'Burundi'\n",
            " 'Belgium' 'Benin' 'Burkina Faso' 'Bangladesh' 'Bulgaria' 'Bahrain'\n",
            " 'Bosnia and Herzegovina' 'Belarus' 'Belize' 'Bolivia' 'Brazil' 'Bhutan'\n",
            " 'Botswana' 'Canada' 'Switzerland' 'Chile' 'China' 'Côte d’Ivoire'\n",
            " 'Cameroon' 'Congo, Dem. Rep.' 'Congo, Rep.' 'Colombia' 'Comoros'\n",
            " 'Costa Rica' 'Cuba' 'Cyprus' 'Czech Republic' 'Germany' 'Djibouti'\n",
            " 'Denmark' 'Dominican Republic' 'Algeria' 'Ecuador' 'Egypt, Arab Rep.'\n",
            " 'Spain' 'Estonia' 'Ethiopia' 'Finland' 'Fiji' 'France'\n",
            " 'Micronesia, Fed. Sts.' 'Gabon' 'United Kingdom' 'Georgia' 'Ghana'\n",
            " 'Guinea' 'Gambia, The' 'Equatorial Guinea' 'Greece' 'Guatemala'\n",
            " 'Honduras' 'Croatia' 'Haiti' 'Hungary' 'Indonesia' 'Isle of Man' 'India'\n",
            " 'Ireland' 'Iran, Islamic Rep.' 'Iraq' 'Israel' 'Italy' 'Jordan' 'Japan'\n",
            " 'Kazakhstan' 'Kenya' 'Kyrgyz Republic' 'Cambodia' 'Kiribati'\n",
            " 'Korea, Rep.' 'Kuwait' 'Lao PDR' 'Lebanon' 'Liberia' 'Libya' 'Sri Lanka'\n",
            " 'Lithuania' 'Latvia' 'Morocco' 'Moldova' 'Madagascar' 'Maldives' 'Mexico'\n",
            " 'Marshall Islands' 'Macedonia, FYR' 'Mali' 'Myanmar' 'Montenegro'\n",
            " 'Mongolia' 'Northern Mariana Islands' 'Mozambique' 'Mauritania' 'Malawi'\n",
            " 'Malaysia' 'Namibia' 'Niger' 'Nigeria' 'Nicaragua' 'Netherlands' 'Norway'\n",
            " 'Nepal' 'New Zealand' 'Oman' 'Pakistan' 'Panama' 'Peru' 'Philippines'\n",
            " 'Palau' 'Papua New Guinea' 'Poland' 'Portugal' 'Paraguay'\n",
            " 'West Bank and Gaza' 'Qatar' 'Romania' 'Russian Federation' 'Rwanda'\n",
            " 'Saudi Arabia' 'Senegal' 'Solomon Islands' 'Sierra Leone' 'El Salvador'\n",
            " 'Somalia' 'Serbia' 'South Sudan' 'Slovak Republic' 'Slovenia' 'Sweden'\n",
            " 'Syrian Arab Republic' 'Togo' 'Thailand' 'Tajikistan' 'Turkmenistan'\n",
            " 'Timor-Leste' 'Tonga' 'Tunisia' 'Turkey' 'Tuvalu' 'Tanzania' 'Uganda'\n",
            " 'Ukraine' 'Uruguay' 'United States' 'Uzbekistan' 'Venezuela, RB'\n",
            " 'Vietnam' 'Vanuatu' 'Samoa' 'Kosovo' 'Yemen, Rep.' 'South Africa'\n",
            " 'Zambia' 'Zimbabwe' nan]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How it works:**\n",
        "\n",
        "- The df['country_name'] accesses the country_name column in the DataFrame.\n",
        "\n",
        "- The .unique() function then returns an array of the unique values in this column, meaning it will list all the different countries present in the dataset.\n",
        "\n",
        "**What to expect:** This code will display a list of all unique country names found in the dataset, allowing you to quickly identify the countries represented. For example, you may see country names like 'Afghanistan', 'Brazil', 'India', and many others. This step helps confirm the geographical scope of the data, which is critical when analyzing waste management practices across different countries."
      ],
      "metadata": {
        "id": "q_-xaf8zMu1g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**2.2 Inspecting the Columns in the Dataset**\n",
        "\n",
        "To better understand the structure of the dataset, it's important to check the column names. This can help you know what data you have available to work with. The following code prints a list of all the column names in the dataset."
      ],
      "metadata": {
        "id": "lxb6lV9vW2Wv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2.2\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezvuy0i8Wi4l",
        "outputId": "71db86ef-aabe-49d3-8b40-98feed1a4a37"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['iso3c', 'region_id', 'country_name', 'income_id', 'city_name', 'additional_data_annual_budget_for_waste_management_year', 'additional_data_annual_solid_waste_budget_year', 'additional_data_annual_swm_budget_2017_year', 'additional_data_annual_swm_budget_year', 'additional_data_annual_waste_budget_year', 'additional_data_collection_ton', 'additional_data_number_of_scavengers_on_dumpsites_number', 'additional_data_other_user_fees_na', 'additional_data_swm_contract_arrangement_1_year_contract_period', 'additional_data_swm_contract_arrangement_3_year_contract_period', 'additional_data_total_annual_costs_to_collect_and_dispose_of_city_s_waste_year', 'additional_data_total_swm_expenditures_year', 'additional_data_total_waste_management_budget_year', 'communication_list_of_channels_through_which_the_city_collects_feedback_from_it_residents_on_issues_related_to_solid_waste_services_na', 'communication_summary_of_key_solid_waste_information_made_periodically_available_to_the_public_na', 'composition_food_organic_waste_percent', 'composition_glass_percent', 'composition_metal_percent', 'composition_other_percent', 'composition_paper_cardboard_percent', 'composition_plastic_percent', 'composition_rubber_leather_percent', 'composition_wood_percent', 'composition_yard_garden_green_waste_percent', 'informal_sector_child_waste_pickers_number', 'informal_sector_child_waste_pickers_percent', 'informal_sector_female_waste_pickers_number', 'informal_sector_female_waste_pickers_percent', 'informal_sector_social_safeguards_for_waste_pickers_list', 'informal_sector_total_waste_pickers_number', 'institutional_framework_department_dedicated_to_solid_waste_management_na', 'institutional_framework_environmental_assessment_for_solid_waste_management_in_the_past_5_years_na', 'institutional_framework_information_system_for_solid_waste_management_na', 'institutional_framework_performed_a_social_assessment_for_solid_waste_management_in_the_past_5_years_na', 'institutional_framework_unit_enforcing_solid_waste_issues_in_the_city_such_as_illegal_dumping_or_littering_na', 'legal_framework_long_term_integrated_solid_waste_master_plan_na', 'legal_framework_master_plan_is_being_implemented_na', 'legal_framework_solid_waste_management_rules_and_regulations_na', 'n_waste_pickers_number_of_waste_pickers_number_of_people', 'percent_informal_sector_percent_collected_by_informal_sector_percent', 'population_population_number_of_people', 'primary_collection_mode_form_of_primary_collection_na', 'separation_breakdonw_cans_and_metals_na', 'separation_breakdonw_glass_na', 'separation_breakdonw_organics_na', 'separation_breakdonw_other_na', 'separation_breakdonw_paper_cardboard_na', 'separation_breakdonw_plastics_and_packaging_na', 'separation_existence_of_source_separation_na', 'subisidies_other_subsidies_or_transfers_na', 'subisidies_subsidies_or_transfers_from_a_central_government_authority_na', 'total_msw_total_msw_generated_tons_year', 'transportation_distance_from_city_center_to_main_landfill_or_dumpsite_km', 'transportation_distance_km', 'transportation_distance_km_year', 'transportation_distance_na', 'transportation_distance_total_km_day', 'transportation_scale_calibration_and_operation_status_na', 'transportation_scale_usage_na', 'transportation_transfer_station_or_collection_point_aggregation_na', 'transportation_transfer_station_or_colletion_point_aggregation_na', 'transportation_transfer_stations_needed_number', 'transportation_transfer_stations_needed_na', 'transportation_transfer_stations_operational_number', 'transportation_transfer_stations_operational_na', 'transportation_trips_per_year_na', 'transportation_trips_per_year_trips_year', 'waste_collection_cost_recovery_commercial_fee_amount_na', 'waste_collection_cost_recovery_household_fee_amount_na', 'waste_collection_cost_recovery_household_fee_to_private_agents_non_municipal_na', 'waste_collection_cost_recovery_metadata_commercial_fee_type_na', 'waste_collection_cost_recovery_metadata_household_fee_type_na', 'waste_collection_cost_recovery_metadata_main_method_of_household_billing_na', 'waste_collection_cost_recovery_total_collection_revenues_na', 'waste_collection_cost_recovery_total_commercial_fees_collected_na', 'waste_collection_cost_recovery_total_household_fees_collected_na', 'waste_collection_coverage_total_percent_of_geographic_area_percent_of_geographic_area', 'waste_collection_coverage_total_percent_of_households_percent_of_households', 'waste_collection_coverage_total_percent_of_population_percent_of_population', 'waste_collection_coverage_total_percent_of_waste_percent_of_waste', 'waste_disposal_cost_recovery_metadata_disposal_fee_type_na', 'waste_disposal_cost_recovery_other_revenues_na', 'waste_disposal_cost_recovery_per_unit_disposal_cost_na', 'waste_disposal_cost_recovery_total_disposal_revenues_na', 'waste_disposal_cost_recovery_total_revenues_from_compost_na', 'waste_disposal_cost_recovery_total_revenues_from_recycling_na', 'waste_management_cost_controlled_landfill_na', 'waste_management_cost_incineration_na', 'waste_management_cost_open_dump_na', 'waste_management_cost_other_na', 'waste_management_cost_recycling_na', 'waste_management_cost_sanitary_landfill_landfill_gas_system_na', 'waste_to_energy_cost_recovery_amount_of_energy_distributed_through_feed_in_tariff_kwh_year', 'waste_to_energy_cost_recovery_amount_of_energy_generated_kwh_year', 'waste_to_energy_cost_recovery_feed_in_tariff_amount_na', 'waste_to_energy_cost_recovery_total_revenues_from_energy_recovery_na', 'waste_treatment_advanced_thermal_treatment_percent', 'waste_treatment_anaerobic_digestion_percent', 'waste_treatment_compost_percent', 'waste_treatment_controlled_landfill_percent', 'waste_treatment_incineration_percent', 'waste_treatment_landfill_unspecified_percent', 'waste_treatment_open_dump_percent', 'waste_treatment_other_percent', 'waste_treatment_recycling_percent', 'waste_treatment_sanitary_landfill_landfill_gas_system_percent', 'waste_treatment_unaccounted_for_percent', 'waste_treatment_waterways_marine_percent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How it works:**\n",
        "\n",
        "- df.columns retrieves the names of all the columns in the DataFrame df.\n",
        "\n",
        "- The .tolist() method converts these column names from an Index object into a regular Python list, which makes it easier to display and manipulate the list of columns.\n",
        "\n",
        "**Why this is important:** This step helps you quickly understand the structure of the dataset. It provides a list of all the attributes or features available in the dataset, such as 'country_name', 'city_name', 'total_msw_total_msw_generated_tons_year', and so on. Knowing the column names is crucial when you want to refer to specific attributes of the data for analysis.\n",
        "\n",
        "**What to expect:** When you run this code, it will print a list of column names, allowing you to see the variables available in the dataset. For example, you might see a list that includes 'country_name', 'city_name', 'waste_collection_cost_recovery_household_fee_amount_na', 'waste_management_cost_open_dump_na', etc. This list helps guide you in selecting the columns you want to analyze or clean.\n"
      ],
      "metadata": {
        "id": "icAglm29NCrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----\n",
        "## **2.3 Converting Data Types for Numeric Columns**\n",
        "Some columns in the dataset may not be in the appropriate format for numerical analysis. For example, columns containing numbers might have been loaded as text. To perform calculations on these columns, we need to ensure they are converted into numeric types.\n",
        "\n",
        "For instance, the column 'total_msw_total_msw_generated_tons_year' represents the total amount of municipal solid waste generated, and we need it to be numeric to perform any mathematical operations on it.\n"
      ],
      "metadata": {
        "id": "9_znXFVmZDfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2.3\n",
        "df[\"total_msw_total_msw_generated_tons_year\"] = pd.to_numeric(\n",
        "    df[\"total_msw_total_msw_generated_tons_year\"],\n",
        "    errors=\"coerce\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "SOhl0q3A5IuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What this does:** The pd.to_numeric() function attempts to convert the values in the specified column into numeric values. The errors=\"coerce\" argument ensures that any non-numeric values are replaced with NaN, allowing us to handle any invalid or missing data appropriately.\n",
        "\n",
        "**Why this is important:** Converting the column to numeric format is necessary to perform mathematical operations such as summing or averaging the values. Without this step, attempting to perform calculations on non-numeric values would lead to errors."
      ],
      "metadata": {
        "id": "ZoN0Ucm0PWwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Summary of Step 2: Data Exploration and Preprocessing**\n",
        "By the end of Step 2, you should have a clear understanding of the structure and content of the dataset. We will have explored the columns, identified any missing or malformed data, and ensured that all data types are appropriate for analysis. This prepares the dataset for the next steps, where we will perform more detailed analysis and visualizations."
      ],
      "metadata": {
        "id": "GYcPmSM_ZZ_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font size=\"6\">**Step 3: Data Analysis and Insights**</font>\n",
        "\n",
        "In Step 3, we take the data we acquired and begin analyzing it to uncover trends and insights. This step focuses on understanding the patterns in waste generation, waste diversion (recycling and composting), and comparing these patterns across countries and cities. We will break down the data in several key ways:\n",
        "\n",
        "1. **Total Waste by Country**: We will calculate the total waste generated by each country, which will help us identify the biggest waste producers globally.\n",
        "2. **Waste Diversion Rate**: We will calculate how much waste is being diverted from landfills by looking at recycling and composting rates.\n",
        "3. **Top Cities for Waste Diversion**: We will identify the cities with the highest and lowest diversion rates, shedding light on where waste management practices are most effective.\n",
        "4. **Cities Generating the Most Waste**: We will also look at which cities are generating the most waste, highlighting urban areas with the highest waste challenges.\n",
        "\n",
        "Now, let's go through each analysis step by step, explain the code we’ll use, and discuss the purpose behind it."
      ],
      "metadata": {
        "id": "y6YxRsWOaazy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**3.1 Total MSW by Country**\n",
        "In this step, we group the data by country and calculate the total waste generated by each country. Sorting the countries in descending order allows us to identify the largest producers of municipal solid waste."
      ],
      "metadata": {
        "id": "wsys-OZjbyp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.1\n",
        "waste_by_country = df.groupby(\"country_name\")[\"total_msw_total_msw_generated_tons_year\"].sum()\n",
        "waste_by_country = waste_by_country.sort_values(ascending=False)\n",
        "print(waste_by_country.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tX8minq57wD",
        "outputId": "1d3c96b2-809a-46f1-d83d-922861768acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "country_name\n",
            "India                 2.075418e+07\n",
            "Brazil                8.903979e+06\n",
            "Russian Federation    7.989254e+06\n",
            "China                 7.903000e+06\n",
            "Saudi Arabia          6.580000e+06\n",
            "Mexico                5.784915e+06\n",
            "Egypt, Arab Rep.      5.475000e+06\n",
            "Pakistan              5.280906e+06\n",
            "Vietnam               4.909250e+06\n",
            "South Africa          4.540491e+06\n",
            "Name: total_msw_total_msw_generated_tons_year, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How this works:**\n",
        "We use the groupby() function to group the data by the \"country_name\" column. Then, we sum the total waste generated (total_msw_total_msw_generated_tons_year) for each country. Finally, we sort the results in descending order to identify the countries that generate the most waste.\n",
        "\n",
        "**Why it's important:**\n",
        "This step helps us see which countries are the largest contributors to municipal solid waste. Understanding the top waste-producing countries can help target areas for policy changes or improvements in waste management practices.\n",
        "\n"
      ],
      "metadata": {
        "id": "7BWfPgYQ0jgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**3.2 City-Level Waste Analysis**\n",
        "We now look at waste generation on a city level. We’ll extract the city name and the total waste generated and sort the cities by their waste generation."
      ],
      "metadata": {
        "id": "7ayoNYtHcYAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.2\n",
        "all_city_waste = df[[\"city_name\", \"total_msw_total_msw_generated_tons_year\"]].copy()\n",
        "all_city_waste = all_city_waste.dropna()\n",
        "all_city_waste = all_city_waste.sort_values(by=\"total_msw_total_msw_generated_tons_year\", ascending=False)"
      ],
      "metadata": {
        "id": "R98hWdJz7RR8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How this works:**\n",
        "Here, we create a new DataFrame that only contains the \"city_name\" and \"total_msw_total_msw_generated_tons_year\" columns. We drop any rows with missing data (dropna()), and then we sort the cities by the total waste generated in descending order.\n",
        "\n",
        "**Why it's important:**\n",
        "This step gives us a view of which cities are generating the most waste, helping to pinpoint urban areas with the greatest waste management challenges."
      ],
      "metadata": {
        "id": "fSMgPSQ0XxiO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**3.3 Waste Diversion Rate Calculation**\n",
        "We now calculate the waste diversion rate for each city by adding the recycling and composting percentages.\n"
      ],
      "metadata": {
        "id": "QngD1BpLcKgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.3\n",
        "df[\"diversion_rate\"] = df[\"waste_treatment_recycling_percent\"] + df[\"waste_treatment_compost_percent\"]"
      ],
      "metadata": {
        "id": "_C0f1N_A6l3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How this works:**\n",
        "We add the \"waste_treatment_recycling_percent\" and \"waste_treatment_compost_percent\" columns to create a new column, \"diversion_rate,\" which represents the percentage of waste that is diverted from landfills.\n",
        "\n",
        "**Why it's important:**\n",
        "This step helps us understand how much of the waste is being managed through recycling and composting, reducing the burden on landfills. This is a key metric in sustainable waste management practices."
      ],
      "metadata": {
        "id": "qA18-EtPYDPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**3.4 Average Diversion Rate by Country**\n",
        "Next, we group the data by country and calculate the average diversion rate."
      ],
      "metadata": {
        "id": "bSxmeeddcvL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.4\n",
        "diversion_by_country = df.groupby(\"country_name\")[\"diversion_rate\"].mean()\n",
        "diversion_by_country = diversion_by_country.sort_values(ascending=False)\n",
        "print(diversion_by_country.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSEbM1gZ64db",
        "outputId": "7d6350f9-f649-4b2e-9d54-7a9d7063e414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "country_name\n",
            "Belgium                 67.000\n",
            "Korea, Rep.             65.000\n",
            "Thailand                60.550\n",
            "Iran, Islamic Rep.      54.000\n",
            "Canada                  51.650\n",
            "India                   45.394\n",
            "France                  40.510\n",
            "United Arab Emirates    29.000\n",
            "Mexico                  24.790\n",
            "Lebanon                 22.500\n",
            "Name: diversion_rate, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How this works:**\n",
        "We use groupby() again to group the data by country, then we calculate the average diversion rate for each country. Sorting the values in descending order allows us to identify the countries with the highest diversion rates.\n",
        "\n",
        "**Why it's important:**\n",
        "This helps us identify which countries are most effective in diverting waste from landfills, which is a critical measure of sustainability and environmental responsibility."
      ],
      "metadata": {
        "id": "58HdecpbYNJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**3.5 Top and Bottom Cities for Waste Diversion**\n",
        "Finally, we find the cities with the highest and lowest diversion rates, providing insight into where waste diversion practices are most successful and where improvements are needed."
      ],
      "metadata": {
        "id": "soVII7jOc79j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.5\n",
        "top_diversion = df[[\"city_name\", \"diversion_rate\"]].sort_values(by=\"diversion_rate\", ascending=False).head(10)\n",
        "low_diversion = df[[\"city_name\", \"diversion_rate\"]].sort_values(by=\"diversion_rate\", ascending=True).head(10)\n",
        "\n",
        "print(\"Top 10 Cities for Diversion:\")\n",
        "print(top_diversion)\n",
        "\n",
        "print(\"\\nBottom 10 Cities for Diversion:\")\n",
        "print(low_diversion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5Hc3jii5f8W",
        "outputId": "78f1fc1d-25ad-4d59-8079-6a29eedf6637"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Cities for Diversion:\n",
            "            city_name  diversion_rate\n",
            "148  Pimpri-Chinchwad           79.70\n",
            "171        Coimbatore           73.40\n",
            "177            Mysore           72.00\n",
            "26              Liege           67.00\n",
            "201             Seoul           65.00\n",
            "139             Kochi           61.90\n",
            "318           Bangkok           60.55\n",
            "149            Kanpur           54.66\n",
            "180            Tehran           54.00\n",
            "52            Toronto           51.65\n",
            "\n",
            "Bottom 10 Cities for Diversion:\n",
            "                                  city_name  diversion_rate\n",
            "123                             Tegucigalpa            3.00\n",
            "208  Dehiwala Mt. Lavinia Municipal Council            3.90\n",
            "151                                  Tenali            4.75\n",
            "45                                   La Paz            5.00\n",
            "178                                Warangal            5.32\n",
            "324                                Vavaâ€™u            6.60\n",
            "210                             Trincomalee            9.70\n",
            "344                                   Hanoi           10.20\n",
            "82                                  Algiers           11.00\n",
            "272                              Wellington           11.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How this works:**\n",
        "We create two new DataFrames: one for the cities with the highest diversion rates (top_diversion) and another for the cities with the lowest diversion rates (low_diversion). We then print the top and bottom 10 cities.\n",
        "\n",
        "**Why it's important:**\n",
        "By identifying the top and bottom cities, we can learn from the best practices of leading cities in waste diversion and understand the challenges faced by cities with low diversion rates.\n",
        "\n"
      ],
      "metadata": {
        "id": "rXBxRO4Y5jwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**3.6 Top Cities for Waste Generation**\n",
        "Lastly, we identify the cities that generate the most waste, which will give us a better understanding of the urban centers with the greatest waste management challenges.\n"
      ],
      "metadata": {
        "id": "2Qly92qHdP2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3.6\n",
        "top_cities_waste = df[[\"city_name\", \"total_msw_total_msw_generated_tons_year\"]]\n",
        "top_cities_waste = top_cities_waste.sort_values(by=\"total_msw_total_msw_generated_tons_year\", ascending=False).head(10)\n",
        "print(top_cities_waste)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEn7uU9q69dO",
        "outputId": "f7eee777-1f5c-4eb0-df4f-8b30b553961a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          city_name  total_msw_total_msw_generated_tons_year\n",
            "58          Beijing                                7903000.0\n",
            "296          Moscow                                5500000.0\n",
            "85            Cairo                                5475000.0\n",
            "227    MÃ©xico City                                4705945.0\n",
            "48        Sao Paulo                                4700000.0\n",
            "302          Riyadh                                4380000.0\n",
            "318         Bangkok                                4190000.0\n",
            "110          London                                3560990.0\n",
            "47   Rio De Janeiro                                3368499.0\n",
            "201           Seoul                                3353985.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How this works:\n",
        "We extract the \"city_name\" and \"total_msw_total_msw_generated_tons_year\" columns from the original DataFrame and sort them in descending order to show the cities generating the most waste.\n",
        "\n",
        "Why it's important:\n",
        "This step allows us to see which cities have the highest waste generation. By identifying these cities, we can target resources and strategies for improving waste management in these areas, which face the biggest challenges.\n"
      ],
      "metadata": {
        "id": "igEqyMJmYVQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# <font size=\"5\">**Summery of Step 3: Data Analysis and Insights**</font>\n",
        "\n",
        "In this step, we transformed raw waste data into meaningful insights by grouping, calculating, and ranking key metrics. We identified the countries and cities that generate the most municipal solid waste, as well as those leading and lagging in waste diversion efforts.  \n",
        "By understanding these patterns, we now have a clear view of where waste management is most effective and where challenges are greatest. These insights will guide the next steps in deeper analysis and potential solutions for more sustainable waste management practices."
      ],
      "metadata": {
        "id": "L--1W4_LdpVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font size=\"6\">**Step 4: Save and Export the Cleaned Data**</font>\n",
        "\n",
        "After exploring, cleaning, and analyzing our dataset, the final step is to save the processed information for future use.  \n",
        "Instead of visualizing the data through charts, in this project we are exporting the cleaned dataset into a new CSV file.  \n",
        "This ensures that all the work we've done — from formatting numbers correctly to selecting relevant columns — is preserved and easy to share, reuse, or further analyze.\n",
        "\n",
        "Saving your work into a CSV file is a critical habit in data projects. It acts like a \"checkpoint\" where you can always return without needing to redo all the previous processing steps.\n"
      ],
      "metadata": {
        "id": "qjYAMBhUfb4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_city_waste.to_csv(\"all_city_waste.csv\", index=False)"
      ],
      "metadata": {
        "id": "1My1nrXr2Llu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How and Why:**\n",
        "\n",
        "- to_csv() is a pandas function that writes the DataFrame into a .csv file.\n",
        "\n",
        "- We set index=False so that the DataFrame index (row numbers) are not saved as a separate column in the CSV file, keeping the output clean.\n",
        "\n",
        "- This new file all_city_waste.csv contains the names of the cities and their total municipal solid waste (MSW) generated — ready for reporting, visualization, or further modeling.\n",
        "\n",
        "By doing this, you lock in all the hard work and create a lightweight version of the dataset that is easy to share and work with later.This save and download csv"
      ],
      "metadata": {
        "id": "3msf3dau52gr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# <font size=\"5\">**Summary for Step 4**</font>\n",
        "\n",
        "In this final step, we exported our cleaned and sorted dataset into a CSV file called `all_city_waste.csv`.  \n",
        "This file contains key information about each city’s total municipal solid waste generation, which is now easy to access without re-running all the cleaning and processing steps.  \n",
        "Saving cleaned datasets is an essential practice in any data workflow — it not only protects your work but also sets you up for efficient future analysis, collaboration, or presentation."
      ],
      "metadata": {
        "id": "VcmXqUz1f9An"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font size=\"6\">**Final Project Summary**</font>\n",
        "\n",
        "In this project, we explored municipal solid waste management data from the World Bank Group.  \n",
        "We started by connecting to Google Drive and accessing the raw dataset, ensuring we had the right environment to work with large data files.  \n",
        "Next, we performed an initial inspection of the data, reviewing available columns and unique country names to understand the scope and variety of information captured.  \n",
        "We then moved into cleaning and analyzing the data — converting important columns to numeric types, summarizing waste generation by country and city, and calculating diversion rates to see how well different cities and countries manage recycling and composting efforts.  \n",
        "Finally, we exported a clean, ready-to-use CSV file that holds valuable insights for future use, reporting, or further visualization.\n",
        "\n",
        "Throughout this project, we practiced essential data handling skills: loading, inspecting, cleaning, analyzing, and saving — key stages in any serious data science or analytics workflow.  \n",
        "By the end, we transformed a large and messy dataset into a clear, structured resource that answers important questions about global waste management trends.\n"
      ],
      "metadata": {
        "id": "c_GRUbb1gNxk"
      }
    }
  ]
}